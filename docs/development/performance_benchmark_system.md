# FastQTools æ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä¸º FastQTools é¡¹ç›®è®¾è®¡äº†å®Œæ•´çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿï¼Œç”¨äºç›‘æ§æ€§èƒ½å˜åŒ–ã€è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’ŒéªŒè¯ä¼˜åŒ–æ•ˆæœã€‚

## ğŸ¯ æ€§èƒ½æµ‹è¯•ç›®æ ‡

### 1. æµ‹è¯•è¦†ç›–èŒƒå›´
- **æ–‡ä»¶ I/O æ€§èƒ½**: è¯»å–ã€å†™å…¥ã€å‹ç¼©å¤„ç†
- **å†…å­˜ä½¿ç”¨æ•ˆç‡**: å†…å­˜åˆ†é…ã€ç¼“å­˜ç­–ç•¥ã€å¯¹è±¡æ± æ•ˆç‡
- **CPU è®¡ç®—æ€§èƒ½**: åºåˆ—å¤„ç†ã€è´¨é‡è®¡ç®—ã€ç»Ÿè®¡ç®—æ³•
- **å¹¶å‘å¤„ç†æ€§èƒ½**: çº¿ç¨‹æ‰©å±•æ€§ã€é”ç«äº‰ã€åŒæ­¥å¼€é”€
- **ç«¯åˆ°ç«¯æ€§èƒ½**: å®Œæ•´å·¥ä½œæµç¨‹çš„æ€§èƒ½è¡¨ç°

### 2. æ€§èƒ½æŒ‡æ ‡
- **ååé‡**: æ¯ç§’å¤„ç†çš„è®°å½•æ•°å’Œç¢±åŸºæ•°
- **å»¶è¿Ÿ**: å•ä¸ªè®°å½•çš„å¤„ç†æ—¶é—´
- **å†…å­˜ä½¿ç”¨**: å³°å€¼å†…å­˜ä½¿ç”¨å’Œå†…å­˜åˆ†é…é¢‘ç‡
- **CPU åˆ©ç”¨ç‡**: å¤šæ ¸åˆ©ç”¨æ•ˆç‡å’Œè®¡ç®—å¯†åº¦
- **å¯æ‰©å±•æ€§**: éšæ•°æ®é‡å’Œçº¿ç¨‹æ•°å˜åŒ–çš„æ€§èƒ½è¡¨ç°

## ğŸ—ï¸ æ€§èƒ½æµ‹è¯•æ¶æ„

### 1. æµ‹è¯•æ¡†æ¶ç»“æ„
```
tools/benchmark/
â”œâ”€â”€ performance_benchmark.cpp      # ä¸»åŸºå‡†æµ‹è¯•ç¨‹åº
â”œâ”€â”€ benchmark_suite.h             # åŸºå‡†æµ‹è¯•å¥—ä»¶
â”œâ”€â”€ benchmark_cases/              # å…·ä½“æµ‹è¯•ç”¨ä¾‹
â”‚   â”œâ”€â”€ file_io_benchmarks.cpp
â”‚   â”œâ”€â”€ memory_benchmarks.cpp
â”‚   â”œâ”€â”€ cpu_benchmarks.cpp
â”‚   â”œâ”€â”€ concurrent_benchmarks.cpp
â”‚   â””â”€â”€ end_to_end_benchmarks.cpp
â”œâ”€â”€ benchmark_reporters/          # ç»“æœæŠ¥å‘Šå™¨
â”‚   â”œâ”€â”€ console_reporter.h
â”‚   â”œâ”€â”€ json_reporter.h
â”‚   â””â”€â”€ html_reporter.h
â”œâ”€â”€ benchmark_data/               # æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ data_generator.h
â”‚   â””â”€â”€ workload_profiles.h
â””â”€â”€ benchmark_utils/              # å·¥å…·å‡½æ•°
    â”œâ”€â”€ performance_counter.h
    â”œâ”€â”€ memory_tracker.h
    â””â”€â”€ statistics.h
```

### 2. åŸºå‡†æµ‹è¯•æ ¸å¿ƒç±»
```cpp
// tools/benchmark/benchmark_suite.h
#pragma once

#include <benchmark/benchmark.h>
#include <memory>
#include <vector>
#include <string>
#include <map>

namespace fq::benchmark {

class BenchmarkSuite {
public:
    static auto get_instance() -> BenchmarkSuite&;
    
    // æµ‹è¯•æ³¨å†Œ
    auto register_benchmark(const std::string& name,
                          std::unique_ptr<BenchmarkCase> benchmark) -> void;
    
    // æµ‹è¯•æ‰§è¡Œ
    auto run_benchmarks(const BenchmarkConfig& config) -> BenchmarkResults;
    
    // ç»“æœæŠ¥å‘Š
    auto generate_report(const BenchmarkResults& results,
                        const std::string& format) -> std::string;
    
    // æ€§èƒ½æ¯”è¾ƒ
    auto compare_with_baseline(const BenchmarkResults& current,
                              const BenchmarkResults& baseline) -> PerformanceComparison;
    
private:
    BenchmarkSuite() = default;
    std::map<std::string, std::unique_ptr<BenchmarkCase>> m_benchmarks;
};

// åŸºå‡†æµ‹è¯•åŸºç±»
class BenchmarkCase {
public:
    virtual ~BenchmarkCase() = default;
    virtual auto run(benchmark::State& state) -> void = 0;
    virtual auto get_name() const -> std::string = 0;
    virtual auto get_description() const -> std::string = 0;
    virtual auto get_category() const -> std::string = 0;
};

// åŸºå‡†æµ‹è¯•é…ç½®
struct BenchmarkConfig {
    size_t min_time = 1;           // æœ€å°è¿è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    size_t iterations = 0;         // è¿­ä»£æ¬¡æ•°ï¼ˆ0è¡¨ç¤ºè‡ªåŠ¨ï¼‰
    size_t warmup_iterations = 3;  // é¢„çƒ­è¿­ä»£æ¬¡æ•°
    bool use_real_time = true;     // ä½¿ç”¨çœŸå®æ—¶é—´
    bool measure_memory = true;   // æµ‹é‡å†…å­˜ä½¿ç”¨
    std::string output_format = "console"; // è¾“å‡ºæ ¼å¼
};

// åŸºå‡†æµ‹è¯•ç»“æœ
struct BenchmarkResult {
    std::string name;
    std::string category;
    double mean_time = 0.0;
    double std_dev = 0.0;
    size_t iterations = 0;
    size_t memory_bytes = 0;
    std::map<std::string, double> additional_metrics;
};

struct BenchmarkResults {
    std::vector<BenchmarkResult> results;
    std::string timestamp;
    std::string git_commit;
    std::string system_info;
};

// æ€§èƒ½æ¯”è¾ƒç»“æœ
struct PerformanceComparison {
    std::vector<std::string> improved;
    std::vector<std::string> regressed;
    std::vector<std::string> unchanged;
    double threshold_percent = 5.0;
};

} // namespace fq::benchmark
```

## ğŸ“Š è¯¦ç»†æµ‹è¯•ç”¨ä¾‹

### 1. æ–‡ä»¶ I/O æ€§èƒ½æµ‹è¯•
```cpp
// tools/benchmark/benchmark_cases/file_io_benchmarks.cpp
#include "benchmark_suite.h"
#include "src/modules/io/io.h"
#include "src/modules/fastq/fastq.h"

namespace fq::benchmark {

class FileReadBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "FileRead"; }
    auto get_description() const -> std::string override { 
        return "Measure FASTQ file reading performance"; 
    }
    auto get_category() const -> std::string override { return "I/O"; }
    
    auto run(benchmark::State& state) -> void override {
        auto file_size = state.range(0);
        auto test_file = generate_test_fastq_file(file_size);
        
        for (auto _ : state) {
            auto reader = std::make_unique<FastQReader>(test_file);
            size_t total_records = 0;
            
            while (auto record = reader->read_record()) {
                total_records++;
                state.PauseTiming(); // æš‚åœè®¡æ—¶ï¼Œé¿å…æµ‹é‡éªŒè¯å¼€é”€
                verify_record(*record);
                state.ResumeTiming(); // æ¢å¤è®¡æ—¶
            }
            
            state.SetItemsProcessed(total_records);
            state.SetBytesProcessed(file_size);
        }
    }
};

class FileWriteBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "FileWrite"; }
    auto get_description() const -> std::string override { 
        return "Measure FASTQ file writing performance"; 
    }
    auto get_category() const -> std::string override { return "I/O"; }
    
    auto run(benchmark::State& state) -> void override {
        auto record_count = state.range(0);
        auto read_length = state.range(1);
        auto records = generate_test_records(record_count, read_length);
        auto output_file = get_temp_file_path();
        
        for (auto _ : state) {
            auto writer = std::make_unique<FastQWriter>(output_file);
            
            for (const auto& record : records) {
                state.PauseTiming();
                auto copy = record; // é¿å…æµ‹é‡æ‹·è´å¼€é”€
                state.ResumeTiming();
                
                writer->write_record(copy);
            }
            
            state.SetItemsProcessed(record_count);
            state.SetBytesProcessed(record_count * read_length * 2); // sequence + quality
        }
    }
};

class CompressionBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "Compression"; }
    auto get_description() const -> std::string override { 
        return "Measure compressed file processing performance"; 
    }
    auto get_category() const -> std::string override { return "I/O"; }
    
    auto run(benchmark::State& state) -> void override {
        auto compression_type = static_cast<CompressionType>(state.range(0));
        auto file_size = state.range(1);
        auto test_file = generate_compressed_test_file(file_size, compression_type);
        
        for (auto _ : state) {
            auto reader = std::make_unique<FastQReader>(test_file);
            size_t total_records = 0;
            
            while (auto record = reader->read_record()) {
                total_records++;
                verify_record(*record);
            }
            
            state.SetItemsProcessed(total_records);
            state.SetBytesProcessed(file_size);
        }
    }
};

BENCHMARK_REGISTER_F(FileReadBenchmark, FileRead)
    ->Args({1024 * 1024})    // 1MB
    ->Args({10 * 1024 * 1024})  // 10MB
    ->Args({100 * 1024 * 1024}) // 100MB
    ->Unit(benchmark::kMillisecond);

BENCHMARK_REGISTER_F(FileWriteBenchmark, FileWrite)
    ->Args({1000, 100})     // 1000 records, 100bp
    ->Args({10000, 100})    // 10000 records, 100bp
    ->Args({100000, 100})   // 100000 records, 100bp
    ->Unit(benchmark::kMillisecond);

BENCHMARK_REGISTER_F(CompressionBenchmark, Compression)
    ->Args({static_cast<int>(CompressionType::Gzip), 10 * 1024 * 1024})
    ->Args({static_cast<int>(CompressionType::Bzip2), 10 * 1024 * 1024})
    ->Args({static_cast<int>(CompressionType::Xz), 10 * 1024 * 1024})
    ->Unit(benchmark::kMillisecond);

} // namespace fq::benchmark
```

### 2. å†…å­˜æ€§èƒ½æµ‹è¯•
```cpp
// tools/benchmark/benchmark_cases/memory_benchmarks.cpp
#include "benchmark_suite.h"
#include "src/memory/batch_memory_manager.h"
#include "src/modules/fastq/fastq.h"

namespace fq::benchmark {

class MemoryAllocationBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "MemoryAllocation"; }
    auto get_description() const -> std::string override { 
        return "Measure memory allocation and deallocation performance"; 
    }
    auto get_category() const -> std::string override { return "Memory"; }
    
    auto run(benchmark::State& state) -> void override {
        auto batch_size = state.range(0);
        auto allocation_count = state.range(1);
        
        for (auto _ : state) {
            std::vector<std::unique_ptr<FqBatch>> batches;
            
            for (size_t i = 0; i < allocation_count; ++i) {
                state.PauseTiming();
                // é¢„å…ˆåˆ†é…å†…å­˜ä»¥é¿å…æµ‹é‡åˆ†é…å¼€é”€
                batches.reserve(allocation_count);
                state.ResumeTiming();
                
                batches.push_back(std::make_unique<FqBatch>());
                batches.back()->reserve(batch_size);
            }
            
            state.PauseTiming();
            batches.clear(); // æ¸…ç†å†…å­˜
            state.ResumeTiming();
        }
        
        state.SetItemsProcessed(allocation_count);
    }
};

class ObjectPoolBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "ObjectPool"; }
    auto get_description() const -> std::string override { 
        return "Measure object pool performance vs direct allocation"; 
    }
    auto get_category() const -> std::string override { return "Memory"; }
    
    auto run(benchmark::State& state) -> void override {
        auto use_pool = state.range(0);
        auto operation_count = state.range(1);
        
        auto pool = std::make_unique<FqBatchPool>();
        
        for (auto _ : state) {
            if (use_pool) {
                std::vector<std::unique_ptr<FqBatch>> batches;
                
                for (size_t i = 0; i < operation_count; ++i) {
                    auto batch = pool->acquire();
                    // ä½¿ç”¨å¯¹è±¡æ± 
                    batches.push_back(std::move(batch));
                }
                
                for (auto& batch : batches) {
                    pool->release(std::move(batch));
                }
            } else {
                std::vector<std::unique_ptr<FqBatch>> batches;
                
                for (size_t i = 0; i < operation_count; ++i) {
                    // ç›´æ¥åˆ†é…
                    batches.push_back(std::make_unique<FqBatch>());
                }
            }
            
            state.SetItemsProcessed(operation_count);
        }
    }
};

class MemoryAccessPatternBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "MemoryAccessPattern"; }
    auto get_description() const -> std::string override { 
        return "Measure different memory access patterns"; 
    }
    auto get_category() const -> std::string override { return "Memory"; }
    
    auto run(benchmark::State& state) -> void override {
        auto access_pattern = static_cast<AccessPattern>(state.range(0));
        auto data_size = state.range(1);
        
        auto data = generate_sequential_data(data_size);
        
        for (auto _ : state) {
            switch (access_pattern) {
                case AccessPattern::Sequential:
                    for (size_t i = 0; i < data.size(); ++i) {
                        benchmark::DoNotOptimize(data[i]);
                    }
                    break;
                    
                case AccessPattern::Random:
                    for (size_t i = 0; i < data.size(); ++i) {
                        auto index = rand() % data.size();
                        benchmark::DoNotOptimize(data[index]);
                    }
                    break;
                    
                case AccessPattern::Strided:
                    for (size_t i = 0; i < data.size(); i += 16) {
                        benchmark::DoNotOptimize(data[i]);
                    }
                    break;
            }
            
            state.SetItemsProcessed(data.size());
        }
    }
};

BENCHMARK_REGISTER_F(MemoryAllocationBenchmark, MemoryAllocation)
    ->Args({1000, 1000})     // 1000 records per batch, 1000 allocations
    ->Args({10000, 1000})    // 10000 records per batch, 1000 allocations
    ->Unit(benchmark::kMicrosecond);

BENCHMARK_REGISTER_F(ObjectPoolBenchmark, ObjectPool)
    ->Args({0, 1000})        // Direct allocation
    ->Args({1, 1000})        // Use object pool
    ->Unit(benchmark::kMicrosecond);

BENCHMARK_REGISTER_F(MemoryAccessPatternBenchmark, MemoryAccessPattern)
    ->Args({static_cast<int>(AccessPattern::Sequential), 1000000})
    ->Args({static_cast<int>(AccessPattern::Random), 1000000})
    ->Args({static_cast<int>(AccessPattern::Strided), 1000000})
    ->Unit(benchmark::kMicrosecond);

} // namespace fq::benchmark
```

### 3. CPU è®¡ç®—æ€§èƒ½æµ‹è¯•
```cpp
// tools/benchmark/benchmark_cases/cpu_benchmarks.cpp
#include "benchmark_suite.h"
#include "src/modules/core/core.h"
#include "src/modules/fastq/fastq.h"

namespace fq::benchmark {

class QualityCalculationBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "QualityCalculation"; }
    auto get_description() const -> std::string override { 
        return "Measure quality score calculation performance"; 
    }
    auto get_category() const -> std::string override { return "CPU"; }
    
    auto run(benchmark::State& state) -> void override {
        auto sequence_length = state.range(0);
        auto iterations = state.range(1);
        
        auto quality_string = generate_quality_string(sequence_length);
        
        for (auto _ : state) {
            double total_quality = 0.0;
            
            for (size_t i = 0; i < iterations; ++i) {
                total_quality += QualityScore::calculate_average_quality(quality_string);
            }
            
            benchmark::DoNotOptimize(total_quality);
            state.SetItemsProcessed(iterations);
            state.SetBytesProcessed(iterations * sequence_length);
        }
    }
};

class SequenceValidationBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "SequenceValidation"; }
    auto get_description() const -> std::string override { 
        return "Measure DNA sequence validation performance"; 
    }
    auto get_category() const -> std::string override { return "CPU"; }
    
    auto run(benchmark::State& state) -> void override {
        auto sequence_length = state.range(0);
        auto iterations = state.range(1);
        
        auto sequence = generate_dna_sequence(sequence_length);
        
        for (auto _ : state) {
            size_t valid_count = 0;
            
            for (size_t i = 0; i < iterations; ++i) {
                if (SequenceUtils::is_valid_dna(sequence)) {
                    valid_count++;
                }
            }
            
            benchmark::DoNotOptimize(valid_count);
            state.SetItemsProcessed(iterations);
            state.SetBytesProcessed(iterations * sequence_length);
        }
    }
};

class GcContentBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "GcContent"; }
    auto get_description() const -> std::string override { 
        return "Measure GC content calculation performance"; 
    }
    auto get_category() const -> std::string override { return "CPU"; }
    
    auto run(benchmark::State& state) -> void override {
        auto sequence_length = state.range(0);
        auto iterations = state.range(1);
        
        auto sequence = generate_dna_sequence(sequence_length);
        
        for (auto _ : state) {
            double total_gc = 0.0;
            
            for (size_t i = 0; i < iterations; ++i) {
                total_gc += SequenceUtils::calculate_gc_content(sequence);
            }
            
            benchmark::DoNotOptimize(total_gc);
            state.SetItemsProcessed(iterations);
            state.SetBytesProcessed(iterations * sequence_length);
        }
    }
};

BENCHMARK_REGISTER_F(QualityCalculationBenchmark, QualityCalculation)
    ->Args({100, 10000})     // 100bp, 10000 iterations
    ->Args({150, 10000})     // 150bp, 10000 iterations
    ->Args({250, 10000})     // 250bp, 10000 iterations
    ->Unit(benchmark::kMicrosecond);

BENCHMARK_REGISTER_F(SequenceValidationBenchmark, SequenceValidation)
    ->Args({100, 10000})     // 100bp, 10000 iterations
    ->Args({150, 10000})     // 150bp, 10000 iterations
    ->Args({250, 10000})     // 250bp, 10000 iterations
    ->Unit(benchmark::kMicrosecond);

BENCHMARK_REGISTER_F(GcContentBenchmark, GcContent)
    ->Args({100, 10000})     // 100bp, 10000 iterations
    ->Args({150, 10000})     // 150bp, 10000 iterations
    ->Args({250, 10000})     // 250bp, 10000 iterations
    ->Unit(benchmark::kMicrosecond);

} // namespace fq::benchmark
```

### 4. å¹¶å‘æ€§èƒ½æµ‹è¯•
```cpp
// tools/benchmark/benchmark_cases/concurrent_benchmarks.cpp
#include "benchmark_suite.h"
#include "src/processing/tbb_processing_pipeline.h"
#include "src/modules/fastq/fastq.h"

namespace fq::benchmark {

class ThreadScalingBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "ThreadScaling"; }
    auto get_description() const -> std::string override { 
        return "Measure thread scaling performance"; 
    }
    auto get_category() const -> std::string override { return "Concurrency"; }
    
    auto run(benchmark::State& state) -> void override {
        auto thread_count = state.range(0);
        auto file_size = state.range(1);
        
        auto test_file = generate_test_fastq_file(file_size);
        
        for (auto _ : state) {
            auto config = create_processing_config();
            config.thread_count = thread_count;
            
            auto pipeline = std::make_unique<TbbProcessingPipeline>(config);
            pipeline->set_input(test_file.string());
            pipeline->set_output(get_temp_file_path());
            
            auto start_time = std::chrono::high_resolution_clock::now();
            auto result = pipeline->run();
            auto end_time = std::chrono::high_resolution_clock::now();
            
            auto duration = std::chrono::duration<double>(end_time - start_time).count();
            state.SetIterationTime(duration);
            
            ASSERT_EQ(result.status, ProcessingStatus::Success);
        }
        
        state.SetItemsProcessed(file_size / 150); // Assuming 150bp reads
        state.SetBytesProcessed(file_size);
    }
};

class LockContentionBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "LockContention"; }
    auto get_description() const -> std::string override { 
        return "Measure lock contention under high concurrency"; 
    }
    auto get_category() const -> std::string override { return "Concurrency"; }
    
    auto run(benchmark::State& state) -> void override {
        auto thread_count = state.range(0);
        auto operation_count = state.range(1);
        
        auto shared_counter = std::make_shared<std::atomic<size_t>>(0);
        auto shared_pool = std::make_shared<FqBatchPool>();
        
        for (auto _ : state) {
            std::vector<std::thread> threads;
            
            auto start_time = std::chrono::high_resolution_clock::now();
            
            for (size_t i = 0; i < thread_count; ++i) {
                threads.emplace_back([operation_count, shared_counter, shared_pool]() {
                    for (size_t j = 0; j < operation_count; ++j) {
                        auto batch = shared_pool->acquire();
                        shared_counter->fetch_add(1);
                        shared_pool->release(std::move(batch));
                    }
                });
            }
            
            for (auto& thread : threads) {
                thread.join();
            }
            
            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration<double>(end_time - start_time).count();
            state.SetIterationTime(duration);
            
            state.SetItemsProcessed(thread_count * operation_count);
        }
    }
};

class ConcurrentStatisticsBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "ConcurrentStatistics"; }
    auto get_description() const -> std::string override { 
        return "Measure concurrent statistics calculation performance"; 
    }
    auto get_category() const -> std::string override { return "Concurrency"; }
    
    auto run(benchmark::State& state) -> void override {
        auto thread_count = state.range(0);
        auto batch_count = state.range(1);
        
        for (auto _ : state) {
            auto calculator = std::make_unique<FqStatistic>(thread_count);
            std::vector<std::future<StatisticsResult>> futures;
            
            auto start_time = std::chrono::high_resolution_clock::now();
            
            for (size_t i = 0; i < thread_count; ++i) {
                auto batch = generate_test_batch(batch_count / thread_count, 150);
                futures.push_back(std::async(std::launch::async, [&calculator, &batch]() {
                    return calculator->calculate_batch(batch);
                }));
            }
            
            StatisticsResult total_result;
            for (auto& future : futures) {
                auto result = future.get();
                total_result.merge(result);
            }
            
            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration<double>(end_time - start_time).count();
            state.SetIterationTime(duration);
            
            state.SetItemsProcessed(batch_count);
            state.SetBytesProcessed(batch_count * 150 * 2); // sequence + quality
        }
    }
};

BENCHMARK_REGISTER_F(ThreadScalingBenchmark, ThreadScaling)
    ->Args({1, 10 * 1024 * 1024})      // 1 thread, 10MB
    ->Args({2, 10 * 1024 * 1024})      // 2 threads, 10MB
    ->Args({4, 10 * 1024 * 1024})      // 4 threads, 10MB
    ->Args({8, 10 * 1024 * 1024})      // 8 threads, 10MB
    ->Args({16, 10 * 1024 * 1024})     // 16 threads, 10MB
    ->Unit(benchmark::kMillisecond);

BENCHMARK_REGISTER_F(LockContentionBenchmark, LockContention)
    ->Args({2, 1000})        // 2 threads, 1000 operations
    ->Args({4, 1000})        // 4 threads, 1000 operations
    ->Args({8, 1000})        // 8 threads, 1000 operations
    ->Args({16, 1000})       // 16 threads, 1000 operations
    ->Unit(benchmark::kMicrosecond);

BENCHMARK_REGISTER_F(ConcurrentStatisticsBenchmark, ConcurrentStatistics)
    ->Args({1, 10000})       // 1 thread, 10000 batches
    ->Args({2, 10000})       // 2 threads, 10000 batches
    ->Args({4, 10000})       // 4 threads, 10000 batches
    ->Args({8, 10000})       // 8 threads, 10000 batches
    ->Unit(benchmark::kMillisecond);

} // namespace fq::benchmark
```

### 5. ç«¯åˆ°ç«¯æ€§èƒ½æµ‹è¯•
```cpp
// tools/benchmark/benchmark_cases/end_to_end_benchmarks.cpp
#include "benchmark_suite.h"
#include "src/processing/processing_pipeline.h"
#include "src/cli/commands/stat_command.h"

namespace fq::benchmark {

class StatCommandBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "StatCommand"; }
    auto get_description() const -> std::string override { 
        return "Measure end-to-end stat command performance"; 
    }
    auto get_category() const -> std::string override { return "EndToEnd"; }
    
    auto run(benchmark::State& state) -> void override {
        auto file_size = state.range(0);
        auto test_file = generate_test_fastq_file(file_size);
        
        for (auto _ : state) {
            fq::cli::StatCommand stat_command;
            
            std::vector<std::string> args = {
                "fastqtools", "stat",
                "--input", test_file.string(),
                "--output", get_temp_file_path().string()
            };
            
            auto start_time = std::chrono::high_resolution_clock::now();
            
            // Parse arguments and execute
            cxxopts::Options options("stat", "FastQ file statistics");
            // Add options similar to main program
            auto result = options.parse(args.size(), args.data());
            
            stat_command.execute(args.size(), const_cast<char**>(args.data()));
            
            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration<double>(end_time - start_time).count();
            state.SetIterationTime(duration);
            
            state.SetItemsProcessed(file_size / 150); // Assuming 150bp reads
            state.SetBytesProcessed(file_size);
        }
    }
};

class FilterCommandBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "FilterCommand"; }
    auto get_description() const -> std::string override { 
        return "Measure end-to-end filter command performance"; 
    }
    auto get_category() const -> std::string override { return "EndToEnd"; }
    
    auto run(benchmark::State& state) -> void override {
        auto file_size = state.range(0);
        auto test_file = generate_test_fastq_file(file_size);
        
        for (auto _ : state) {
            fq::cli::FilterCommand filter_command;
            
            std::vector<std::string> args = {
                "fastqtools", "filter",
                "--input", test_file.string(),
                "--output", get_temp_file_path().string(),
                "--min-quality", "20",
                "--min-length", "50"
            };
            
            auto start_time = std::chrono::high_resolution_clock::now();
            
            filter_command.execute(args.size(), const_cast<char**>(args.data()));
            
            auto end_time = std::chrono::high_resolution_clock::now();
            auto duration = std::chrono::duration<double>(end_time - start_time).count();
            state.SetIterationTime(duration);
            
            state.SetItemsProcessed(file_size / 150);
            state.SetBytesProcessed(file_size);
        }
    }
};

class ProcessingPipelineBenchmark : public BenchmarkCase {
public:
    auto get_name() const -> std::string override { return "ProcessingPipeline"; }
    auto get_description() const -> std::string override { 
        return "Measure complete processing pipeline performance"; 
    }
    auto get_category() const -> std::string override { return "EndToEnd"; }
    
    auto run(benchmark::State& state) -> void override {
        auto file_size = state.range(0);
        auto complexity = state.range(1); // 1=simple, 2=medium, 3=complex
        
        auto test_file = generate_test_fastq_file(file_size);
        
        for (auto _ : state) {
            auto config = create_processing_config();
            
            // Add processing steps based on complexity
            if (complexity >= 1) {
                config.mutators.push_back({"quality_trimmer", {{"min_quality", 20}}});
            }
            if (complexity >= 2) {
                config.mutators.push_back({"length_trimmer", {{"min_length", 50}}});
            }
            if (complexity >= 3) {
                config.mutators.push_back({"adapter_trimmer", {{"adapter_sequence", "AGATCGGAAG"}}});
                config.predicates.push_back({"max_n_ratio", {{"max_ratio", 0.1}}});
            }
            
            auto pipeline = std::make_unique<TbbProcessingPipeline>(config);
            pipeline->set_input(test_file.string());
            pipeline->set_output(get_temp_file_path());
            
            auto start_time = std::chrono::high_resolution_clock::now();
            auto result = pipeline->run();
            auto end_time = std::chrono::high_resolution_clock::now();
            
            auto duration = std::chrono::duration<double>(end_time - start_time).count();
            state.SetIterationTime(duration);
            
            state.SetItemsProcessed(file_size / 150);
            state.SetBytesProcessed(file_size);
            
            ASSERT_EQ(result.status, ProcessingStatus::Success);
        }
    }
};

BENCHMARK_REGISTER_F(StatCommandBenchmark, StatCommand)
    ->Args({10 * 1024 * 1024})    // 10MB
    ->Args({100 * 1024 * 1024})   // 100MB
    ->Args({1000 * 1024 * 1024})  // 1GB
    ->Unit(benchmark::kMillisecond);

BENCHMARK_REGISTER_F(FilterCommandBenchmark, FilterCommand)
    ->Args({10 * 1024 * 1024})    // 10MB
    ->Args({100 * 1024 * 1024})   // 100MB
    ->Args({1000 * 1024 * 1024})  // 1GB
    ->Unit(benchmark::kMillisecond);

BENCHMARK_REGISTER_F(ProcessingPipelineBenchmark, ProcessingPipeline)
    ->Args({10 * 1024 * 1024, 1})  // 10MB, simple
    ->Args({10 * 1024 * 1024, 2})  // 10MB, medium
    ->Args({10 * 1024 * 1024, 3})  // 10MB, complex
    ->Args({100 * 1024 * 1024, 1}) // 100MB, simple
    ->Args({100 * 1024 * 1024, 2}) // 100MB, medium
    ->Args({100 * 1024 * 1024, 3}) // 100MB, complex
    ->Unit(benchmark::kMillisecond);

} // namespace fq::benchmark
```

## ğŸ”§ æ€§èƒ½æµ‹è¯•å·¥å…·

### 1. æ€§èƒ½è®¡æ•°å™¨
```cpp
// tools/benchmark/benchmark_utils/performance_counter.h
#pragma once

#include <chrono>
#include <memory>
#include <string>

namespace fq::benchmark {

class PerformanceCounter {
public:
    static auto get_instance() -> PerformanceCounter&;
    
    // CPU æ€§èƒ½è®¡æ•°å™¨
    auto get_cpu_usage() -> double;
    auto get_process_cpu_time() -> double;
    auto get_system_cpu_time() -> double;
    
    // å†…å­˜æ€§èƒ½è®¡æ•°å™¨
    auto get_memory_usage() -> size_t;
    auto get_peak_memory_usage() -> size_t;
    auto get_page_faults() -> size_t;
    
    // I/O æ€§èƒ½è®¡æ•°å™¨
    auto get_bytes_read() -> size_t;
    auto get_bytes_written() -> size_t;
    auto get_disk_operations() -> size_t;
    
    // è‡ªå®šä¹‰è®¡æ•°å™¨
    auto start_timing(const std::string& name) -> void;
    auto stop_timing(const std::string& name) -> double;
    auto get_timing(const std::string& name) -> double;
    
    // ç»Ÿè®¡ä¿¡æ¯
    auto get_system_info() -> std::string;
    auto get_process_info() -> std::string;
    
private:
    PerformanceCounter();
    struct Impl;
    std::unique_ptr<Impl> m_impl;
};

// RAII è®¡æ—¶å™¨
class ScopedTimer {
public:
    explicit ScopedTimer(const std::string& name);
    ~ScopedTimer();
    
private:
    std::string m_name;
    std::chrono::high_resolution_clock::time_point m_start_time;
};

} // namespace fq::benchmark
```

### 2. å†…å­˜è·Ÿè¸ªå™¨
```cpp
// tools/benchmark/benchmark_utils/memory_tracker.h
#pragma once

#include <cstddef>
#include <string>
#include <vector>

namespace fq::benchmark {

class MemoryTracker {
public:
    static auto get_instance() -> MemoryTracker&;
    
    // å†…å­˜åˆ†é…è·Ÿè¸ª
    auto allocation_hook() -> void;
    auto deallocation_hook() -> void;
    
    // å†…å­˜ç»Ÿè®¡
    auto get_total_allocated() -> size_t;
    auto get_total_freed() -> size_t;
    auto get_current_usage() -> size_t;
    auto get_peak_usage() -> size_t;
    auto get_allocation_count() -> size_t;
    auto get_deallocation_count() -> size_t;
    
    // å†…å­˜åˆ†é…åˆ†æ
    auto get_allocation_size_distribution() -> std::vector<std::pair<size_t, size_t>>;
    auto get_allocation_hotspots() -> std::vector<std::pair<std::string, size_t>>;
    
    // é‡ç½®ç»Ÿè®¡
    auto reset() -> void;
    
    // ç”ŸæˆæŠ¥å‘Š
    auto generate_report() -> std::string;
    
private:
    MemoryTracker() = default;
    struct Impl;
    std::unique_ptr<Impl> m_impl;
};

// RAII å†…å­˜è·Ÿè¸ªå™¨
class ScopedMemoryTracker {
public:
    explicit ScopedMemoryTracker(const std::string& name);
    ~ScopedMemoryTracker();
    
    auto get_peak_memory() const -> size_t;
    auto get_total_allocations() const -> size_t;
    
private:
    std::string m_name;
    size_t m_start_memory;
    size_t m_start_allocations;
};

} // namespace fq::benchmark
```

### 3. æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
```cpp
// tools/benchmark/benchmark_data/data_generator.h
#pragma once

#include <filesystem>
#include <string>
#include <vector>

namespace fq::benchmark {

class TestDataGenerator {
public:
    struct DataSpec {
        size_t record_count = 0;
        size_t read_length = 0;
        double quality_mean = 30.0;
        double quality_std = 5.0;
        double gc_content = 0.5;
        bool variable_length = false;
        size_t min_length = 0;
        size_t max_length = 0;
        double adapter_contamination = 0.0;
        std::string adapter_sequence = "AGATCGGAAG";
    };
    
    // ç”Ÿæˆæ ‡å‡† FASTQ æ–‡ä»¶
    static auto generate_fastq_file(const DataSpec& spec,
                                   const std::filesystem::path& output_path) -> void;
    
    // ç”Ÿæˆå‹ç¼©æ–‡ä»¶
    static auto generate_compressed_file(const DataSpec& spec,
                                        const std::filesystem::path& output_path,
                                        CompressionType type) -> void;
    
    // ç”ŸæˆæŸåæ•°æ®
    static auto generate_corrupted_file(const DataSpec& spec,
                                      const std::filesystem::path& output_path,
                                      CorruptionType type) -> void;
    
    // ç”Ÿæˆä¸åŒè´Ÿè½½ç‰¹å¾çš„æ•°æ®
    static auto generate_workload_profile(WorkloadProfile profile,
                                        const std::filesystem::path& output_path) -> void;
    
private:
    static auto generate_records(const DataSpec& spec) -> std::vector<FqRecord>;
    static auto add_corruption(std::vector<FqRecord>& records, 
                             CorruptionType type) -> void;
};

} // namespace fq::benchmark
```

## ğŸ“Š æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ

### 1. æŠ¥å‘Šç”Ÿæˆå™¨
```cpp
// tools/benchmark/benchmark_reporters/html_reporter.h
#pragma once

#include "benchmark_suite.h"
#include <string>

namespace fq::benchmark {

class HtmlReporter {
public:
    static auto generate_report(const BenchmarkResults& results,
                              const std::filesystem::path& output_path) -> void;
    
    static auto generate_comparison_report(const BenchmarkResults& current,
                                         const BenchmarkResults& baseline,
                                         const std::filesystem::path& output_path) -> void;
    
    static auto generate_trend_report(const std::vector<BenchmarkResults>& history,
                                   const std::filesystem::path& output_path) -> void;
    
private:
    static auto generate_html_header(const std::string& title) -> std::string;
    static auto generate_summary_table(const BenchmarkResults& results) -> std::string;
    static auto generate_performance_charts(const BenchmarkResults& results) -> std::string;
    static auto generate_system_info(const BenchmarkResults& results) -> std::string;
    static auto generate_html_footer() -> std::string;
};

} // namespace fq::benchmark
```

### 2. æŒç»­é›†æˆé›†æˆ
```yaml
# .github/workflows/benchmark.yml
name: Performance Benchmark

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  benchmark:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build
      run: |
        mkdir -p build
        cd build
        cmake .. -DCMAKE_BUILD_TYPE=Release
        make -j$(nproc)
    
    - name: Run Benchmarks
      run: |
        cd build
        ./tools/benchmark/performance_benchmark \
          --benchmark_format=json \
          --benchmark_out=benchmark_results.json
    
    - name: Compare with Baseline
      run: |
        cd build
        python3 ../scripts/compare_benchmarks.py \
          benchmark_results.json \
          baseline_results.json \
          --threshold=5.0 \
          --output=comparison_report.html
    
    - name: Upload Results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: |
          build/benchmark_results.json
          build/comparison_report.html
    
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('build/benchmark_results.json', 'utf8'));
          const comparison = JSON.parse(fs.readFileSync('build/comparison_report.json', 'utf8'));
          
          let comment = `## ğŸ“Š Performance Benchmark Results\n\n`;
          comment += `### Summary\n`;
          comment += `- **Improved**: ${comparison.improved.length} benchmarks\n`;
          comment += `- **Regressed**: ${comparison.regressed.length} benchmarks\n`;
          comment += `- **Unchanged**: ${comparison.unchanged.length} benchmarks\n\n`;
          
          if (comparison.regressed.length > 0) {
            comment += `### âš ï¸ Performance Regressions\n`;
            comparison.regressed.forEach(regression => {
              comment += `- ${regression.name}: ${regression.change}%\n`;
            });
          }
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
```

## ğŸ¯ ä½¿ç”¨æŒ‡å—

### 1. è¿è¡ŒåŸºå‡†æµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
./tools/benchmark/performance_benchmark

# è¿è¡Œç‰¹å®šç±»åˆ«çš„æµ‹è¯•
./tools/benchmark/performance_benchmark --benchmark_filter=I/O

# ç”Ÿæˆ JSON æŠ¥å‘Š
./tools/benchmark/performance_benchmark --benchmark_format=json --benchmark_out=results.json

# ç”Ÿæˆ HTML æŠ¥å‘Š
./tools/benchmark/performance_benchmark --benchmark_format=html --benchmark_out=results.html
```

### 2. æ€§èƒ½å›å½’æ£€æµ‹
```bash
# ç”ŸæˆåŸºçº¿ç»“æœ
./tools/benchmark/performance_benchmark --benchmark_out=baseline.json

# è¿è¡Œå½“å‰ç‰ˆæœ¬
./tools/benchmark/performance_benchmark --benchmark_out=current.json

# æ¯”è¾ƒç»“æœ
python3 scripts/compare_benchmarks.py current.json baseline.json --threshold=5.0
```

### 3. æŒç»­ç›‘æ§
```bash
# è®¾ç½®å®šæ—¶ä»»åŠ¡
crontab -e
# æ·»åŠ ï¼šæ¯å¤©å‡Œæ™¨è¿è¡Œæ€§èƒ½æµ‹è¯•
0 0 * * * /path/to/fastqtools/scripts/daily_benchmark.sh
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

é€šè¿‡å®æ–½è¿™ä¸ªæ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿï¼ŒFastQTools é¡¹ç›®å°†è·å¾—ï¼š

1. **æ€§èƒ½å›å½’æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹æ€§èƒ½é€€åŒ–
2. **ç“¶é¢ˆè¯†åˆ«**: ç²¾ç¡®å®šä½æ€§èƒ½ç“¶é¢ˆ
3. **ä¼˜åŒ–éªŒè¯**: éªŒè¯æ€§èƒ½ä¼˜åŒ–æ•ˆæœ
4. **æŒç»­ç›‘æ§**: é•¿æœŸæ€§èƒ½è¶‹åŠ¿ç›‘æ§
5. **æ–‡æ¡£åŒ–æ€§èƒ½**: å»ºç«‹æ€§èƒ½åŸºçº¿å’Œç›®æ ‡

è¿™ä¸ªæ€§èƒ½åŸºå‡†æµ‹è¯•ç³»ç»Ÿä¸º FastQTools é¡¹ç›®æä¾›äº†ä¼ä¸šçº§çš„æ€§èƒ½ä¿è¯ä½“ç³»ã€‚